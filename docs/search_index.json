[["index.html", "Nhật Ký Data Lời nói đầu", " Nhật Ký Data Lê Huỳnh Đức 2024-03-04 Lời nói đầu "],["tháng-01-2024.html", "Chương 1 Tháng 01 2024 Ngày 15 Ngày 16 Ngày 17 Ngày 18", " Chương 1 Tháng 01 2024 Ngày 15 Hôm nay mình đã đọc gì 1.0.1 Efficient Feature Selection via Genetic Algorithms Đây là một bài viết trên Medium nói về việc sử dụng Generic Algorithms. Generic Algorithms Tiếng Việt được gọi là Giải thuật di truyền, là thuật toán đầu tiên mình học được ngay khi bắt đầu học môn Máy học thống kê ở trường. Mình đã áp dụng nó vào bài toán tìm nghiệm xấp xỉ của một phương trình đa thức. Về Giải thuật di truyền có các định nghĩa chính: Population (dân số) Xác suất đột biến Xác suất lai chéo Chiến lược chọn các phần tử con Để hiểu rõ hơn các bạn có thể tham khảo ở Wiki (https://en.wikipedia.org/wiki/Genetic_algorithm) Tóm gọn lại bài viết này xem danh sách N features là một chuỗi gen có độ dài là N và chứa các giá trị 1 nghĩa là feature tại vị trí i sẽ được chọn và bằng 0 nghĩa là feature tại vị trí i sẽ không được chọn Thuật toán sẽ khởi tạo Một quần thể gồm 8 chuỗi gen khác nhau và tiến hành đột biến hoặc lai chéo giữa chúng để ra chuỗi gen mới -&gt; tập Features đã được chọn. Sau đó sẽ dùng phương pháp đánh giá. Bài này sử dụng code dựa trên thư viện https://github.com/DEAP/deap Và code đầy đủ có tại https://github.com/FlorinAndrei/fast_feature_selection 1.0.2 Data Envelopment Analysis Hôm nay mình đã đọc Chương một của cuốn sách Data Envelopment Analysis Của tác giả William W. Cooper , Lawrence M. Seiford , Kaoru Tone. Cuốn sách này tuy xuất bản năm 2007 nhưng khá có ích đối với việc mình đang làm là đánh giá chất lượng. Đánh giá Hiệu suất là gì​? Khi chúng ta có đầu vào, và nhận được kết quả, chúng ta hay đánh giá hiệu suất của kết quả xem với đầu vào như thế thì kết quả liệu có tốt không.​ Một số ví dụ cơ bản: Giá thành/sản phẩm, Lợi nhuận/sản phẩm.​ \\[ \\frac{Output}{Input} \\] Công thức trên được gọi là thước đo hiệu quả.​ Chúng ta có thể mở rộng công thức trên với Nhiều đầu vào (Inputs) và nhiều đầu ra (Outputs)​ Độ dốc của đường nối với mỗi điểm và gốc tọa độ tương ứng với Sales/ Employee ( hiệu quả).​ Đường có độ dốc cao nhất (nối với điểm B) được gọi là Efficient Frontier (Đường biên hiệu quả).​ Các điểm sẽ nằm cùng 1 phía so với đường thẳng, hoặc ở trên, hoặc ở dưới.​ Vì đường biên này bao bọc các điểm dữ liệu, nên phân tích này được gọi là Data Envelopment Analysis.​ Chúng ta có thể vẽ một đường thống kê hồi quy y=0.622x để ước lượng mối quan hệ tuyến tính giữa input và output.​ Đường hồi quy này đi qua chính giữa của tập dữ liệu, do đó chúng ta có thể xem các điểm ở phía trên đường là hiệu quả tốt và điểm dưới là chưa tốt, khoảng cách giữa điểm tới đường hồi quy chính ta mức độ hiệu quả/không hiệu quả​ Khoảng cách từ các điểm đến đường Efficient Frontier nêu lên độ lệch so với điểm tốt nhất​ Ngày 16 1.0.3 Chuẩn bị tài liệu cho khóa Data Analyst Tập trung vào các nội dung như Lambda function là gì, map, reduce,filter kết hợp cùng với lambda function Iterable và Iterator là gì Iterable là kiểu cấu trúc có thể dùng vòng lặp for được, thay vì dùng index mình có thể for phần tử trong cấu trúc Iterator là kiểu duyệt của các Iterable, để tạo iterator mình có thể áp dụng hàm iter(a). Để duyệt phần tử kế tiếp mình dùng next(). Nếu không còn phần tử nào sẽ trả về lỗi StopIteration Các kiểu Iterator như enumerate, zip Tiếp theo là List comprehension, dict comprehension Các kiểu collections mới Counter : dùng để đếm nhanh số lượng các phần tử Defaultdict: handle lỗi khi key không có trong dict, thường trả về giá trị mặc định tùy mình set Namedtuple: định nghĩa một tuple có cấu trúc, tên của từng phần tử 1.0.4 Step-by-Step Guide to Designing a User-Friendly Application Là một nhà khoa học dữ liệu, các kỹ năng thu thập, xử lý và phân tích dữ liệu cũng như đào tạo các mô hình phức tạp của bạn sẽ cung cấp những hiểu biết sâu sắc có giá trị giúp hướng dẫn các bên liên quan chính đưa ra quyết định đúng đắn. Tuy nhiên, bạn có thể thường xuyên phải đối mặt với những thách thức trong việc truyền đạt những kết quả này một cách hiệu quả. Việc dựa vào các tài liệu tĩnh có thể không thể hiện được toàn bộ tiềm năng của mô hình của bạn và thu hút sự quan tâm của người dùng doanh nghiệp. Không có gì có thể khó chịu hơn việc công việc của bạn không được tận dụng tối đa tiềm năng của nó. Đây là nơi một ứng dụng năng động, tương tác phát huy tác dụng. Nó biến công việc của bạn thành một công cụ sống động, mời các bên liên quan đến một môi trường khám phá, cộng tác và ra quyết định theo thời gian thực. Xác định mục tiêu ứng dụng Đầu tiên, điều quan trọng là phải xác định được câu hỏi “Tại sao phải tạo ra ứng dụng”, dưới đây là một số câu hỏi gợi ý Ứng dụng của bạn giải quyết vấn đề gì Nó tăng thêm giá trị cho người dùng như thế nào Những điểm chính rút ra từ ứng dụng là gì Mục tiêu App Người dùng muốn biết họ nên gọi cho ai từ một danh sách rộng lớn Giới thiệu khách hàng mới tiềm năng Người dùng muốn xác định ai có nguy cơ rời đi và chiến lược nào có thể giữ chân họ Đề xuất chiến lược giữ chân khách hàng Người dùng muốn đảm bảo mô hình đáng tin cậy của mô hình Chứng minh độ tin cậy và độ chính xác Xác định người dùng của bạn Ví dụ Sale manager: Không quá kỹ thuật Ưu tiên các sơ đồ thông thường và giải thích văn bản Cần hành động kịp thời hàng ngày Quan tâm đến hiệu suất của mô hình và khả năng giải thích Lập kế hoạch cho cấu trúc và tính năng của ứng dụng Ngày 17 1.0.5 Chữa bài Là một bài về dự đoán chất lượng nguồn nước gồm các thông số cơ bản như Location Temp pH EC Do Turb TN TP Và nhãn là Toc Phần này mình có đọc code của một thầy bên Hàn, thầy áp dùng fill outlier bằng IQR rất đơn giản loại bỏ các điểm nằm ngoài Q3 + 3 * IQR và Q1 - 3 * IQR. Lần này thầy dùng hệ số bằng 3 chứ không bằng 1 như mặc dịnh Sau đó thầy vẽ các phân phối của nó ra trước khi xử lý def show_hist_by_target(df, columns): sns.set(font_scale=1.0) sns.set_style(&#39;white&#39;) for column in columns: fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 3)) sns.boxplot(data=df, y=column, ax=axs[0]) sns.histplot(data=df, x=column, ax=axs[1], kde=True, bins=200, stat=&#39;frequency&#39;) plt.subplots_adjust(hspace=0.8,wspace=0.6) Tiếp theo thầy sử dụng ktest và normal test xem dữ liệu có bị skewness không for k in df.columns: test_stat, p_val = stats.kstest(df[k], &#39;norm&#39;) print(&quot;Test-statistics : {:.3f}, p-value : {:.3f}, skewness : {:.3f}&quot;.format(test_stat, p_val, df[k].skew())) # (Kolmogorov-Smirnov) kstest / shapiro for k in df.columns: test_stat, p_val = stats.kstest(df[k], &#39;norm&#39;) print(&quot;Test-statistics : {:.3f}, p-value : {:.3f}, skewness : {:.3f}&quot;.format(test_stat, p_val, df[k].skew())) # (Kolmogorov-Smirnov) kstest / shapiro Thầy dùng R2 score để tính, sử dụng 2 cách là dùng thư vienj sklearn và dùng công thức điều chỉnh ############################################################################################################## def adj_r2_score(y_true, y_pred, p=x_train_scaled.shape[1]): return 1-(1-r2_score(y_true, y_pred)) * (len(y_true)-1) / (len(y_true) - p - 1) Thầy dùng Scaler là Robust Scaler, trước đó đã test box cox nhưng vì có tồn tại dữ liệu âm nên không dùng box-cox. Giải pháp của mình là: Remove các dòng âm và bằng 0 -&gt; khoảng 500 dòng trên 300k dòng Dùng thuật toán yeo-johnson tương tự như box cox nhưng có thể áp dụng cho số âm Mình cũng hướng dẫn bạn ấy sử dụng KFold thay vì train_test_split vì train_test_split có khả năng bị bias vì không xác thực chéo trên toàn bộ dữ liệu( bị bias). Kết quả mình test thử train_test_split với nhiều seed khác nhau thì kết quả R2 không đồng đều. Ngày 18 1.0.6 Kết hợp ChatGPT vào Named Entity Recognition 1.0.6.1 Giới thiệu về Named Entity Recognition Named Entity Recogtition là bài toán nhận dạng thực thể, một số thực thể thông dùng như PERSON : Tên người LOCATION: Địa chỉ DATE: Ngày tháng năm ORG: Tên các tổ chức. Ngoài ra tùy vào yêu cầu của mỗi bài toán có thể có những Named Entity Recoginition. Bài toán trích xuất thông tin xe thì có thêm BRAND, MODEL, YEAR, CAR_TYPE …. Bài toán trích xuất thông tin từ các sản phẩm trên các sàn thương mại điện tử : BRAND, PRODUCT_NAME, SIZE, PRICE Dựa vào các thông tin được trích xuất đó, chúng ta có thể làm các bài toán như sau: - Lưu trữ dữ liệu : sau khi trích xuất thông tin về một item, chúng ta có thể lưu trữ các thông tin đó vào các bảng có cấu trúc hoặc lưu vào SQL - Các bài toán Recommendation: Dựa vào các thông tin trích xuất đó, chúng ta có thể đưa ra gợi ý các sản phẩm cho người dùng. Ví dụ như: - Người dùng đang xem các bài báo liên quan đến xe, chúng ta có thể trích xuất hãng xe, dòng xe từ bài báo mà người dùng đọc, sau đó gợi ý các sản phẩm xe cùng với hãng đó. - Product Matching: Trên các sàn thương mại điện tử, nhiều nhà cung cấp có thể cùng bán một sản phẩm, việc trích xuất thông tin của các sản phẩm có thể giúp gom các sản phẩm giống nhau về cùng một nhóm, qua đó có thể nắm bắt được giá cả, sức mua của sản phẩm đó. 1.0.6.2 ChatGPT Để có thể nhận diện được các thực thể, thông thường chúng ta sẽ huấn luyện các mô hình với dữ liệu huấn luyện được gán nhãn trước. Một số ví dụ về huấn luyện các mô hình https://medium.com/@mjghadge9007/building-your-own-custom-named-entity-recognition-ner-model-with-spacy-v3-a-step-by-step-guide-15c7dcb1c416 https://www.analyticsvidhya.com/blog/2022/06/how-to-train-an-ner-model-with-huggingface/ https://blog.futuresmart.ai/building-a-custom-ner-model-with-spacy-a-step-by-step-guide Ngoài ra chúng ta cũng có thể tận dụng sức mạnh của chatGPT dưới đây là một ví dụ về prompt để lấy brand và model xe messages=[ {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Perform Name Entity Recognition task \\ to extract car brand and car model name from paragraphs&quot;}, {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Output format: a string v1:v2 where v1 is car brand and v2 is car model for each input.\\ If not found car brand then v1 = None. If not found car model then v2 = None&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: text} ], Kết quả trả ra text brand model 0 Toyota Land Cruise LC300 is a good and powerfu… Toyota Land Cruiser LC300 1 I am a big fan of Jeep Wrangle Rubicon, an off… Jeep Wrangler Rubicon 2 Black Friday, buy cars at great prices None None 1.0.7 Phân tích Shop Branch Bài toán của mình là tìm ra các vị trí A, B sao cho - Bắt đầu từ A: Profit của các chi nhánh tăng vọt - Sau khi qua B: Profit của các chi nhánh đi ngang Sau đó đưa ra các điểm Ti, Tj là lần lượt là thời gian đạt được điểm A và điểm B Dựa vào đó, phòng ban Kinh doanh sẽ biết được các chi nhánh nào đang hoạt động không hiệu quả để đưa ra các giải pháp phù hợp "],["tháng-02-2024.html", "Chương 2 Tháng 02 2024 Ngày 20 Ngày 21", " Chương 2 Tháng 02 2024 Ngày 20 Hôm nay mình đã đọc gì 2.0.1 Cách visualize counts và labels cho histogram dùng seaborn và numpy Thông thường, khi visualize mặc định histogram của seaborn sẽ không thể hiện tất cả các nhãn của bins và số lượng mỗi bin import numpy as np import seaborn as sns np.random.seed(42) x = np.random.uniform(size=200) sns.histplot(x, bins=10) Như trên sẽ rất khó theo dõi các giá trị và số lượng, do đó cần phải tìm được giá trị của các bin và số lượng. May mắn thay seaborn histogram tương tự numpy nên ta có thể dùng hàm np.histogram counts, bin_labels = np.histogram(x, bins=10) print(len(counts), counts) print(len(bin_labels), bin_labels) 10 [22 24 20 24 11 19 20 18 18 24] 11 [0.00552212 0.1036586 0.20179508 0.29993156 0.39806804 0.49620453 0.59434101 0.69247749 0.79061397 0.88875045 0.98688694] Các bạn có thể thấy với tham số bins đưa vào chỉ có 10 trong khi kết quả nhãn bin_labels lại có 11 giá trị, trong đó giá trị đầu là giá trị nhỏ nhất của x và giá trị cuối là giá trị cao nhất của x. Do đó khoảng đầu tiên của bin đầu tiên có giá trị nằm từ [0.00552212, 0.1036586) Để kiểm tra xem có đúng thể không, ví dụ kiểm tra bin đầu tiên có phải 22 phần tử không len(x[(x&gt;=bin_labels[0]) &amp; (x&lt;bin_labels[1])]) 22 Chính xác!! Dùng matplotlib để plot text import matplotlib.pyplot as plt counts, bin_labels = np.histogram(x, bins=10) ax = sns.histplot(x, bins=10) bin_heights = [p.get_height() if p.get_height() &gt; 0 else 0.1 for p in ax.patches] # Hiển thị giá trị count từng bin for i in range(len(bin_heights)): plt.text(ax.patches[i].get_x() + ax.patches[i].get_width() / 2, bin_heights[i], str(int(bin_heights[i])), fontsize=14, ha=&#39;center&#39;, va=&#39;bottom&#39;) mids = [rect.get_x() + rect.get_width() / 2 for rect in ax.patches] labels = [(round(i,2),round(j,2)) for i,j in zip(bin_labels[:-1], bin_labels[1:])] ax.set_xticks(mids, labels=labels, fontsize=14, rotation=90) Ngày 21 Nhận ra rằng violinplot có vẻ không phù hợp bằng nhiều histogram plot, vì violinplot chỉ show kde distribution chứ k show histogram plot, do đó không biết được chính xác bin nào đang cao nhất "],["tháng-03-2024.html", "Chương 3 Tháng 03 2024 Ngày 3", " Chương 3 Tháng 03 2024 Ngày 3 https://towardsdatascience.com/location-analytics-use-cases-that-every-data-scientist-should-know-740b708a2504 Làm sao để xây dựng chiến lược mở rộng chi nhánh tốt nhất https://predikdata.com/how-to-create-the-best-branch-expansion-strategy/ Location intelligence Location Intelligence là một kỹ thuật phân tích dữ liệu nâng cao. Nó sử dụng thông tin địa lý để khám phá các patterns, xu hướng, và mối quan hệ dựa trên dữ liệu. Kỹ thuật này khai tháng sức mạnh của thông tin địa lý để tìm insight từ dữ liệu. Bằng cách kết hợp giữa dữ liệu kinh doanh và dữ liệu không gian, Location Intelligence cung cấp những thông tin có giá trị giúp ra quyết định tốt hơn. Có ba layer trong LI Layer 1: Geographical Layer 2: Store locations Layer 3: Sales data 5 Lợi ích khi sử dụng LI Data-driven dicision-marking: Sử dụng dữ liệu location để đánh giá khả năng tiếp cận của một cửa hàng so với đối thủ cạnh tranh Enhanced customer targeting : Sủ dụng location và heatmap để hiểu hành vi khách hàng https://predikdata.com/heat-maps-for-real-estate-investments/ Cải thiện lợi thế cạnh tranh: Phân tích khả năng di chuyện và lượng người qua lại giữa 2 loại cửa hàng: https://predikdata.com/foot-traffic-in-pharmacies-cvs-pharmacy-vs-walgreens/ Tối ưu hóa chi phí Quản lý nhân sự hợp lý Cách sử dụng LI cho chiến lược mở rộng chi nhánh Xác định thị trường Sử dụng nhân khẩu học, sở thích của người tiêu dùng, hành vi mua hàng và nghiên cứu thị trường để xác định khách hàng lý tưởng của bạn. Thông tin vị trí giúp bạn tìm thấy những khu vực có lượng khách hàng tiềm năng tập trung cao, tập trung nỗ lực mở rộng vào những khu vực hứa hẹn nhất. Phân tích đối thủ Đánh giá bối cảnh cạnh tranh, xác định vị trí và thị phần của đối thủ cạnh tranh. Khám phá những nhu cầu chưa được đáp ứng hoặc những khoảng trống thị trường để xác định cơ hội chi nhánh mới tại thị trường địa phương và quốc tế. Đánh giá khả năng tiếp cận: Ước tính mức độ dễ dàng tiếp cận các địa điểm chi nhánh tiềm năng, bao gồm cơ sở hạ tầng giao thông, mô hình giao thông và tình trạng sẵn có của bãi đậu xe. Các trang web dễ dàng truy cập cho khách hàng và nhân viên góp phần tạo nên sự thành công của chi nhánh Tối ưu hóa chi phí Bất Động Sản (https://predikdata.com/heat-maps-for-real-estate-investments/) Xác định các khu vực có giá bất động sản, giá cho thuê và quy định địa phương tối ưu bằng cách sử dụng thông tin vị trí. Cân bằng chi phí với lượng người qua lại và khả năng hiển thị cao đảm bảo lợi tức đầu tư cao, giúp bạn giảm chi phí và tăng doanh thu. Đánh giá lực lượng lao động địa phương Phân tích thị trường lao động địa phương để đảm bảo có sẵn nhân viên lành nghề và đáng tin cậy. Thông tin vị trí cung cấp thông tin chi tiết về trình độ học vấn, bộ kỹ năng và mức lương trung bình, giúp bạn đưa ra quyết định nhân sự. Quản lý hiệu suất Theo dõi hiệu quả hoạt động của chi nhánh mới bằng các chỉ số hiệu suất chính (KPI) và các tiêu chuẩn đã được thiết lập. Xác định các chi nhánh hoạt động kém hiệu quả và các yếu tố góp phần vào hiệu quả hoạt động của chúng để đưa ra quyết định dựa trên dữ liệu về việc cải thiện hoặc đóng cửa. Việc tích hợp chiến lược tiếp thị của bạn, bao gồm cả phương tiện truyền thông xã hội, với thông tin vị trí cho phép bạn thâm nhập các thị trường mới, nhắm mục tiêu vào các doanh nghiệp nhỏ và thúc đẩy mở rộng quốc tế. Bằng cách khai thác thông tin vị trí để mở rộng thị trường, bạn có thể cung cấp các sản phẩm hoặc dịch vụ phù hợp, tăng sức hấp dẫn đối với khách hàng tiềm năng và đảm bảo thành công lâu dài. Mở rộng chi nhánh sử dụng phân tích dự đoán Các bước để xác định vị trí tốt nhất cho từng điểm bán hàng Bước 1: Thu thập dữ liệu Dữ liệu Demographics như: Tổng số dân, giới tính và tình trạng cư trú /Zip code Các yếu tố kinh thế như sales, giá nhà Thông tin địa lý, vị trí đối thủ cạnh tranh Bước 2: Dự đoán doanh số cửa hàng cấp Zip -&gt; ước tính doanh thu tiềm năng cho từng địa điểm Bước 3: Chọn cấp ZIP có doanh số cao nhất Bước 4: Sử dụng các mô hình để - Hiểu các yếu tố thúc đẩy doanh số bán hàng - Dự báo doanh thu, đồng thời nắm bắt được sức ảnh hưởng “ăn lẫn nhau” (cannibalization) - Dự đoán nhu cầu ở cấp độ sản phẩm / phân khúc - Tạo điểm tương đồng cho cửa hàng Bước 5: Xác định các vị trí có thể tối ưu hóa trông qua kết hợp ví trị các cửa hàng, chi phí, tiềm năng Lặp lại các vị trí lưu trữ có thể có ở cấp Zip Giảm thiểu cannibalization bằng regression model Nhận diện khu vực Zip đang có lợi nhuận cao Bước 6: Xây dựng mô hình hồi quy cấp cửa hàng https://predikdata.com/footfall-analytics-for-site-selection-strategies/ https://predikdata.com/foot-traffic-in-pharmacies-cvs-pharmacy-vs-walgreens/ 3.0.1 Cannibalization Analysis https://locatium.ai/locaium-ai-blog-cannibalization-analysis/ https://targomo.medium.com/introducing-cannibalization-analysis-examine-the-impact-of-competitors-and-network-branches-on-190e08ae002 https://carto.com/blog/cannibalization-analysis-tutorial#:~:text=Cannibalization%20analysis%20evaluates%20the%20impact,impact%20on%20a%20business’%20revenue. https://github.com/CarlitosDev/causalCannibalisation?tab=readme-ov-file "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
